# ğŸ§  AI Resume Analyzer â€“ Smart CV Screening System

> **Built by Hassan Ahmed**  
> A full-stack, AI-powered resume analysis web app with a modern glassmorphism UI, Flask backend, scikit-learn NLP engine, and Neon PostgreSQL database â€” deployable to Vercel in minutes.

---

## âœ¨ Live Demo

> Deploy to Vercel (see below) and share your URL here.

---

## ğŸ¯ Features

| Feature | Description |
|---|---|
| ğŸ“„ Resume Upload | PDF & DOCX support with drag-and-drop |
| ğŸ¤– AI Scoring | TF-IDF cosine similarity weighted score (keyword 60% + skills 20% + format 20%) |
| ğŸ”‘ Keyword Analysis | Matched vs missing JD keywords |
| ğŸ›  Skills Gap | 150+ skills across 8 categories |
| ğŸ“Š ATS Check | Detects formatting issues that block ATS parsers |
| ğŸ’¡ AI Suggestions | Personalised improvement recommendations |
| ğŸ“¥ PDF Report | Download full analysis as a styled PDF |
| ğŸ“ˆ Admin Dashboard | Charts, analytics, and history of all analyses |
| ğŸŒ Neon DB | Cloud PostgreSQL â€” persists data between serverless calls |

---

## ğŸ¨ UI Design

- **Color Palette**: Dark Navy `#0F172A` Â· Neon Aqua `#00F5D4` Â· Pink `#F72585`
- **Style**: Glassmorphism cards Â· Animated particle background Â· Floating hero cards
- **Font**: Inter / Poppins (Google Fonts)
- **Animations**: Score circle counter Â· Confetti on high scores Â· Slide-in cards Â· Progress bars
- **Responsive**: Mobile + Desktop

---

## ğŸ—‚ Project Structure

```
ai-resume-analyzer/
â”‚
â”œâ”€â”€ app.py                  # Flask app + routes + DB models
â”œâ”€â”€ requirements.txt        # Python dependencies
â”œâ”€â”€ vercel.json             # Vercel deployment config
â”œâ”€â”€ Procfile                # Gunicorn for Heroku/Render
â”œâ”€â”€ .env.example            # Environment variable template
â”œâ”€â”€ .gitignore
â”‚
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ parser.py           # PDF/DOCX text extractor
â”‚   â”œâ”€â”€ analyzer.py         # AI analysis engine (TF-IDF, skills, ATS)
â”‚   â””â”€â”€ report.py           # PDF report generator (ReportLab)
â”‚
â”œâ”€â”€ templates/
â”‚   â”œâ”€â”€ base.html           # Shared layout (navbar, footer, particles)
â”‚   â”œâ”€â”€ index.html          # Home page with upload form
â”‚   â”œâ”€â”€ result.html         # Analysis results page
â”‚   â”œâ”€â”€ dashboard.html      # Admin analytics dashboard
â”‚   â””â”€â”€ 404.html            # Error page
â”‚
â”œâ”€â”€ static/
â”‚   â”œâ”€â”€ css/
â”‚   â”‚   â””â”€â”€ style.css       # Full dark/glassmorphism stylesheet
â”‚   â”œâ”€â”€ js/
â”‚   â”‚   â”œâ”€â”€ particles.js    # Animated particle canvas
â”‚   â”‚   â”œâ”€â”€ main.js         # Global utilities
â”‚   â”‚   â”œâ”€â”€ upload.js       # Drag-drop, validation, loading animation
â”‚   â”‚   â”œâ”€â”€ result.js       # Score animation, confetti
â”‚   â”‚   â””â”€â”€ dashboard.js    # Chart.js charts, table search & delete
â”‚   â””â”€â”€ images/
â”‚       â””â”€â”€ favicon.svg
â”‚
â”œâ”€â”€ uploads/                # Temp upload directory (gitignored)
â””â”€â”€ instance/               # SQLite DB for local dev (gitignored)
```

---

## âš™ï¸ Local Development Setup

### 1. Clone the repo

```bash
git clone https://github.com/YOUR_USERNAME/ai-resume-analyzer.git
cd ai-resume-analyzer
```

### 2. Create a virtual environment

```bash
python -m venv venv
source venv/bin/activate        # Windows: venv\Scripts\activate
```

### 3. Install dependencies

```bash
pip install -r requirements.txt
```

### 4. Configure environment

```bash
cp .env.example .env
```

Edit `.env`:
```env
SECRET_KEY=your-secret-key-here
FLASK_DEBUG=true
DATABASE_URL=sqlite:///instance/resume_analyzer.db  # local SQLite
```

### 5. Run the app

```bash
python app.py
```

Open **http://localhost:5000** ğŸ‰

---

## ğŸ—„ Neon Database Setup (Production)

[Neon](https://neon.tech) is a serverless PostgreSQL â€” perfect for Vercel deployments.

1. Go to [neon.tech](https://neon.tech) â†’ **Create a free account**
2. Click **New Project** â†’ choose a region
3. On the **Dashboard** â†’ **Connection Details** â†’ copy the **Connection string**

```
postgresql://user:password@ep-xxx.us-east-2.aws.neon.tech/neondb?sslmode=require
```

4. Set this as your `DATABASE_URL` in Vercel environment variables (see below)

> Tables are created automatically on first run via `db.create_all()`.

---

## ğŸš€ Vercel Deployment

### 1. Push to GitHub

```bash
git init
git add .
git commit -m "Initial commit â€“ AI Resume Analyzer"
git branch -M main
git remote add origin https://github.com/YOUR_USERNAME/ai-resume-analyzer.git
git push -u origin main
```

### 2. Import to Vercel

1. Go to [vercel.com](https://vercel.com) â†’ **Add New Project**
2. Import your GitHub repository
3. Framework: **Other** (Vercel detects `vercel.json` automatically)
4. Click **Environment Variables** â†’ add:

| Key | Value |
|---|---|
| `SECRET_KEY` | `your-strong-random-secret` |
| `DATABASE_URL` | Your Neon connection string |
| `FLASK_DEBUG` | `false` |

5. Click **Deploy** ğŸš€

> **Note on file uploads with Vercel**: Vercel's serverless functions have ephemeral filesystems. The `uploads/` directory is used only temporarily during the request â€” files are processed and then deleted. This is already handled in `app.py`.

---

## ğŸ”‘ Environment Variables Reference

| Variable | Required | Description |
|---|---|---|
| `SECRET_KEY` | âœ… | Flask session secret â€” use a random 32-char hex string |
| `DATABASE_URL` | âœ… | Neon PostgreSQL connection string (or `sqlite:///...` for local) |
| `FLASK_DEBUG` | âŒ | Set to `true` in dev, `false` in prod |
| `OPENAI_API_KEY` | âŒ | Optional â€” for GPT-4 enhanced suggestions |

---

## ğŸ“¡ API Endpoints

| Method | Route | Description |
|---|---|---|
| `GET` | `/` | Home page |
| `POST` | `/upload` | Upload resume + JD â†’ analyze â†’ redirect |
| `GET` | `/result/<uid>` | View analysis result |
| `GET` | `/download-report/<uid>` | Download PDF report |
| `GET` | `/dashboard` | Admin analytics dashboard |
| `GET` | `/api/analyses` | JSON list of all analyses |
| `DELETE` | `/api/delete/<id>` | Delete a single analysis |

---

## ğŸ§ª Database Schema

```sql
CREATE TABLE resume_analysis (
  id                INTEGER PRIMARY KEY,
  uid               VARCHAR(36) UNIQUE NOT NULL,
  filename          VARCHAR(255),
  job_title         VARCHAR(255),
  job_description   TEXT,
  resume_text       TEXT,
  score             INTEGER,
  keyword_score     INTEGER,
  skills_score      INTEGER,
  format_score      INTEGER,
  matched_keywords  TEXT,   -- JSON array
  missing_keywords  TEXT,   -- JSON array
  matched_skills    TEXT,   -- JSON array
  missing_skills    TEXT,   -- JSON array
  suggestions       TEXT,   -- JSON array
  ats_issues        TEXT,   -- JSON array
  created_at        DATETIME
);
```

---

## ğŸ§  AI Scoring Formula

```
Final Score = (Keyword Match Ã— 60%) + (Skills Match Ã— 20%) + (Format Score Ã— 20%)
```

- **Keyword Match**: TF-IDF vectorisation + cosine similarity between resume and JD
- **Skills Match**: Exact/pattern matching against 150+ skills across 8 taxonomy categories
- **Format Score**: Heuristic checks â€” contact info, section headings, word count, action verbs, dates

---

## ğŸ“¦ Tech Stack

| Layer | Tech |
|---|---|
| Backend | Python 3.11 Â· Flask 3 Â· SQLAlchemy 2 |
| AI/NLP | scikit-learn (TF-IDF + cosine similarity) |
| Resume Parsing | pdfplumber Â· PyPDF2 Â· python-docx |
| Database | Neon PostgreSQL (prod) Â· SQLite (local) |
| Frontend | HTML5 Â· CSS3 (Glassmorphism) Â· Vanilla JS |
| Charts | Chart.js 4 |
| PDF Reports | ReportLab |
| Deployment | Vercel (serverless) |
| Version Control | Git + GitHub |

---

## ğŸ›  Extending the Project

### Add OpenAI GPT suggestions

In `utils/analyzer.py`, replace `_generate_suggestions()` with:

```python
import openai, os
client = openai.OpenAI(api_key=os.environ["OPENAI_API_KEY"])

def _gpt_suggestions(resume_text, job_description):
    prompt = f"""Analyze resume vs job description.
Provide:
1. Overall match assessment
2. Top 5 missing skills
3. 5 specific improvement suggestions
4. ATS compatibility feedback

Resume: {resume_text[:2000]}
Job Description: {job_description[:1000]}

Respond in JSON: {{"suggestions": [...], "ats_feedback": [...]}}"""
    
    resp = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": prompt}],
        response_format={"type": "json_object"}
    )
    return json.loads(resp.choices[0].message.content)
```

### Add User Authentication

Install Flask-Login and add `User` model with bcrypt password hashing.

---

## ğŸ“„ License

MIT License â€“ feel free to use, modify, and deploy.

---

## ğŸ‘¨â€ğŸ’» Author

**Hassan Ahmed** â€“ AI Resume Analyzer  
Built with â¤ï¸ using Flask, scikit-learn, and Neon DB.
